# [Проект 1. Анализ вакансий из HeadHunter](https://github.com/Abricovich/Abricovich-sf_data_science/blob/master/project_1/Project%201.ipynb)

## Оглавление
[1. Описание проекта](#Описание-проекта)  
[2. Какой кейс решаем?](#Какой-кейс-решаем)  
[3. Краткая информация о данных](#Краткая-информация-о-данных)  
[4. Этапы работы над проектом](#Этапы-работы-над-проектом)  
[5. Результат](#Результат)    
[6. Выводы](.#Выводы) 

### 1. Описание проекта
Компания HeadHunter хочет построить модель, которая бы автоматически определяла примерный уровень заработной платы, подходящей пользователю, исходя из информации, которую он указал о себе. Задача проекта состоит в преобразовании, подготовке и очистке данных к построению.

[к оглавлению](#оглавление)

### 2. Какой кейс решаем?
Исследовать, очистить, и преобразовать датасет для дальнейшей работы. 

**Условия соревнования**
- Решение оформляется только в Jupyter Notebook
- Каждое задание выполняется в отдельной ячейке, выделенной под задание. Не следует создавать множество ячеек для решения задачи
- Код для каждого задания оформляется в одной-двух jupyter-ячейках (не стоит создавать множество ячеек для решения задачи).
- Решение должно использовать только: переменные, основные структуры данных (списки, словари, множества), циклы, функции, библиотеки numpy, pandas, matplotlib, seaborn, plotly. 
- Код должен быть читаемым и понятным: имена переменных и функций отражают их сущность, важно избегать многострочных конструкций и условий. Код оформлен согласно руководству PEP 8.
- Графики должны содержать название, отражающее их суть, и подписи осей.
- Выводы к графикам оформляются в формате Markdown под самим графиком в отдельной ячейке. Выводы должны быть представлены в виде небольших связанных предложений на русском языке.

**Метрика качества**
- Решение оформлено согласно требованиям "Условия соревнования"
- Соблюдены и выполнены все этапы проекта с заданиями, представлены выводы и графики
- Решение размещено на Git hub


**Что практикуем**

Учимся писать хороший код на Python, практикуем: визуализацию, написание функций,
методы очистки данных, базовые/продвинутые методы работы  с данными в Pandas 

[к оглавлению](#оглавление)

### 3. Краткая информация о данных
- Исходные данные лежат в [google-диске](https://drive.google.com/drive/folders/1oAPHItfSaJ-b1HS2WFBM6S3GkXU8Z0gK?usp=sharing)

[к оглавлению](#оглавление)

### 4. Этапы работы над проектом
- Базовый анализ структуры данных
- Преобразование данных
- Разведывательный анализ(EDA)
- Очистка данных

[к оглавлению](#оглавление)

### 5. Результаты
Проведён базовый и исследовательский анализ структуры данных, получен преобразованный и очищенный датасет от выбросов, дублей, сформированы новые признаки. Добавлена визуализация.

[к оглавлению](#оглавление)

### 6. Выводы
Задачи проекта выполнены полностью с соблюдением всех этапов. Полные выводы по каждому этапу сформированы в Project 1. Датасет подготовлен для следующего этапа.
 
[к оглавлению](#оглавление)